{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# THEORY"
      ],
      "metadata": {
        "id": "phD5oHed7uAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) What is Logistic Regression, and how does it differ from Linear Regression ?"
      ],
      "metadata": {
        "id": "6RZOq3r37t_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression predicts continuous outcomes, while logistic regression predicts categorical outcomes, specifically the probability of belonging to a particular class, using a sigmoid function, which maps any real-valued set of independent variables input into a value between 0 and 1."
      ],
      "metadata": {
        "id": "kRqPoKPQ7t66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) What is the mathematical equation of Logistic Regression ?"
      ],
      "metadata": {
        "id": "MS31e0sA7t2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical equation for logistic regression, which predicts the probability of a binary outcome, is p(x) = 1 / (1 + e^(-(b0 + b1x)))* where 'p(x)' is the predicted probability, 'x' is the input feature, 'b0' is the intercept, 'b1' is the coefficient, and 'e' is the base of the natural logarithm."
      ],
      "metadata": {
        "id": "keyQOAJ47t1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) Why do we use the Sigmoid function in Logistic Regression ?"
      ],
      "metadata": {
        "id": "GApPmSm57txC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sigmoid function is used in logistic regression to map the model's output, which is a linear combination of input features, to a probability between 0 and 1, making it suitable for binary classification tasks."
      ],
      "metadata": {
        "id": "PbP8o20i7twS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) What is the cost function of Logistic Regression ?"
      ],
      "metadata": {
        "id": "0yMAnmar7tr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A cost function is a mathematical function that calculates the difference between the target actual values (ground truth) and the values predicted by the model. A function that assesses a machine learning model's performance also referred to as a loss function or objective function."
      ],
      "metadata": {
        "id": "n5rU1DTV7trK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5) What is Regularization in Logistic Regression? Why is it needed ?"
      ],
      "metadata": {
        "id": "q-IcvTo37tmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization in logistic regression is a technique used to prevent overfitting by adding a penalty term to the cost function, which discourages large coefficients and promotes simpler models that generalize better to unseen data.\n",
        "\n",
        "\n",
        "*   Overfitting: Logistic regression, like other machine learning models, can overfit the training data, meaning it learns the training data too well and performs poorly on new, unseen data\n",
        "*   High Dimensionality: When there are many predictor variables (features), the model can become overly complex and prone to overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "GR2PEX4S7tl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6)  Explain the difference between Lasso, Ridge, and Elastic Net regression."
      ],
      "metadata": {
        "id": "QCPaM_mp7thJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso regression performs feature selection by shrinking coefficients to zero, while Ridge regression shrinks coefficients towards zero but doesn't set them to zero, and Elastic Net combines both, offering a balance between feature selection and coefficient shrinkage."
      ],
      "metadata": {
        "id": "OaTJsofw7tgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7) When should we use Elastic Net instead of Lasso or Ridge ?"
      ],
      "metadata": {
        "id": "XbPr9q6c7tbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Elastic Net when you have many correlated predictors and need a balance between feature selection (like Lasso) and coefficient shrinkage (like Ridge), especially in situations where Lasso might randomly select one correlated variable while ignoring others."
      ],
      "metadata": {
        "id": "Lp42rOMv7tar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8)  What is the impact of the regularization parameter (位) in Logistic Regression ?"
      ],
      "metadata": {
        "id": "ryzzX6sU7tWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In logistic regression, the regularization parameter (位) controls the strength of the penalty applied to the model's coefficients, influencing the model's complexity and preventing overfitting. A higher 位 leads to stronger regularization, smaller coefficients, and a simpler model, while a lower 位 results in weaker regularization, larger coefficients, and a potentially more complex model."
      ],
      "metadata": {
        "id": "hz3tlgHs7tVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9) What are the key assumptions of Logistic Regression ?"
      ],
      "metadata": {
        "id": "rMEYC6nn7tRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key assumptions of logistic regression include a binary or dichotomous dependent variable, independent observations, a linear relationship between the independent variables and the log-odds of the dependent variable, and the absence of multicollinearity among the independent variables."
      ],
      "metadata": {
        "id": "6Ft55bgN7tQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10) What are some alternatives to Logistic Regression for classification tasks ?"
      ],
      "metadata": {
        "id": "1zeUuO017tLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For classification tasks, alternatives to logistic regression include decision trees, random forests, support vector machines (SVMs), neural networks, and Bayesian methods."
      ],
      "metadata": {
        "id": "YL5qUVh47tKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11) What are Classification Evaluation Metrics ?"
      ],
      "metadata": {
        "id": "gAwpWLcC7tGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation metrics for classification include accuracy, precision, recall, F1 score, AUC, confusion matrix, and log loss. These metrics help to understand how well a classification model is performing.\n",
        "\n",
        "\n",
        "*   Accuracy - The ratio of correctly predicted observations to the total observations\n",
        "\n",
        "*   Precision - Evaluates the accuracy of the positive prediction made by the classifier\n",
        "\n",
        "*   Recall - Tells what proportion of actual positive classes was predicted correctly\n",
        "\n",
        "*   F1 score - A measure of the harmonic mean of precision and recall\n",
        "\n",
        "*   AUC - A value between 0 and 1, where a higher value indicates better model performance\n",
        "\n",
        "*   Confusion matrix - Also known as an error matrix, this metric gives us a matrix as output as NXN.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AxeE0Tha7s_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 12) How does class imbalance affect Logistic Regression ?"
      ],
      "metadata": {
        "id": "E1aKb4sk_c2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class imbalance in logistic regression, where one class has significantly more observations than the other, leads to biased models that favor the majority class, potentially misclassifying the minority class and resulting in poor generalization."
      ],
      "metadata": {
        "id": "ham5v704_cit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 13) What is Hyperparameter Tuning in Logistic Regression ?"
      ],
      "metadata": {
        "id": "H1Y8N7kW_cgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning involves selecting the optimal values of hyperparameters, which affect the performance of the Logistic Regression model. Some common hyperparameters that can be tuned include the learning rate, regularization strength, batch size, and number of iterations."
      ],
      "metadata": {
        "id": "joajyopH_ccv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 14) What are different solvers in Logistic Regression? Which one should be used ?"
      ],
      "metadata": {
        "id": "nImmI3qK_cai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For small datasets, 'liblinear' is a good choice, whereas 'sag' and 'saga' are faster for large ones. For multiclass problems, all solvers except 'liblinear' minimize the full multinomial loss, 'liblinear' can only handle binary classification by default."
      ],
      "metadata": {
        "id": "yAWfSKfH_cW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 15) How is Logistic Regression extended for multiclass classification ?"
      ],
      "metadata": {
        "id": "jZ3KdEvy_cUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the multinomial method, the logistic function is replaced with the softmax function which calculates the probability value of the class over n different classes. The only way to implement the multinomial method with logistic regression is to specify the multi_class=\"multinomial\" argument."
      ],
      "metadata": {
        "id": "JNKBJGPeB8GM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16) What are the advantages and disadvantages of Logistic Regression ?"
      ],
      "metadata": {
        "id": "O5VL-mA8B8C7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of Logistic regression -\n",
        "* Easy to set up.\n",
        "* Efficient algorithms.\n",
        "* Reveals interrelationships between variables.\n",
        "* Transforms complex calculations into simple math problems.\n",
        "* Baseline for performance management.\n",
        "\n",
        "Disadvantages of Logistic Regression -\n",
        "* Logistic regression fails to predict a continuous outcome.\n",
        "* Logistic regression assumes linearity between the predicted (dependent) variable and the predictor (independent) variables.\n",
        "* Logistic regression may not be accurate if the sample size is too small."
      ],
      "metadata": {
        "id": "kpzhuF3WB8Ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 17) What are some use cases of Logistic Regression ?"
      ],
      "metadata": {
        "id": "Soz0_Wi1B78i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression, a statistical method for binary classification, finds use in diverse fields like healthcare, finance, and marketing for predicting outcomes like disease risk, fraud detection, and customer churn."
      ],
      "metadata": {
        "id": "IU1xGsOtB76U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 18) What is the difference between Softmax Regression and Logistic Regression ?"
      ],
      "metadata": {
        "id": "Yv4klOjwDiLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax regression is a generalization of logistic regression used for multi-class classification, while logistic regression is primarily used for binary classification, predicting one of two outcomes. Softmax regression uses the softmax function to output probabilities for multiple classes, ensuring they sum to one, whereas logistic regression uses the sigmoid function for binary classification."
      ],
      "metadata": {
        "id": "Fpw5qzanDiIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 19) How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification ?"
      ],
      "metadata": {
        "id": "Q3C3KtaKDiFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiclass classification, choosing between One-vs-Rest (OvR) and Softmax depends on the model's capabilities and the desired outcome.\n",
        "* OVR - which trains a binary classifier for each class against all others, is a good choice when the underlying binary classifier is efficient and scalable.\n",
        "* SOFTMAX - which directly outputs probabilities for all classes, is better suited for models that naturally handle multiclass outputs."
      ],
      "metadata": {
        "id": "3anOL0GEDiDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 20) How do we interpret coefficients in Logistic Regression ?"
      ],
      "metadata": {
        "id": "vTKf88ddES9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In logistic regression, coefficients represent the change in the log-odds of the outcome for a one-unit increase in the predictor variable, holding other variables constant. Exponentiating the coefficient yields the odds ratio, showing the multiplicative change in odds."
      ],
      "metadata": {
        "id": "Cq88V1hEB7Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICAL"
      ],
      "metadata": {
        "id": "3AIbOV2hEXpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "NU1vgKtXEzm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHA_tDMOFBys",
        "outputId": "b3e10433-d801-4494-9fad-76230f4e08ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."
      ],
      "metadata": {
        "id": "-j7DGoeUFduk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Logistic Regression model with L1 regularization (Lasso)\n",
        "model_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_l1.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_l1 = model_l1.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy_l1 = accuracy_score(y_test, y_pred_l1)\n",
        "print(\"Accuracy with L1 regularization:\", accuracy_l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n7mFefNFJCb",
        "outputId": "fae57ec2-7572-4454-c47d-84a82dc03312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with L1 regularization: 0.8947368421052632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) Write a Python program to train Logistic Regression with L2 regularization (Ridge) using Logistic Regression (penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "E-8rb1PiFzqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Logistic Regression model with L2 regularization (Ridge)\n",
        "model_l2 = LogisticRegression(penalty='l2', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_l2.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_l2 = model_l2.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
        "print(\"Accuracy with L2 regularization:\", accuracy_l2)\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"Coefficients:\", model_l2.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzwcBnu3FyZP",
        "outputId": "386171fd-146a-4b70-99fa-a8103ba9c39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with L2 regularization: 0.9736842105263158\n",
            "Coefficients: [[-0.43051977  0.80447008 -2.30452023 -0.95063609]\n",
            " [ 0.62920431 -0.42467439 -0.206373   -0.783506  ]\n",
            " [-0.19868453 -0.37979569  2.51089323  1.73414209]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "Be4TXWMBGQ2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create a Logistic Regression model with Elastic Net regularization\n",
        "model_elasticnet = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_elasticnet.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_elasticnet = model_elasticnet.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy_elasticnet = accuracy_score(y_test, y_pred_elasticnet)\n",
        "print(\"Accuracy with Elastic Net regularization:\", accuracy_elasticnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGJRXWnYGMiQ",
        "outputId": "6240a851-8da6-4387-d7a7-e761dc0a6bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Elastic Net regularization: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5) Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
      ],
      "metadata": {
        "id": "Z_TVfcqZGxAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Logistic Regression model for multiclass classification using 'ovr'\n",
        "model_ovr = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_ovr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_ovr = model_ovr.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "print(\"Accuracy with 'ovr' multiclass:\", accuracy_ovr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV1PxReJGa4k",
        "outputId": "39bad57f-131c-4df3-d296-6662aff9a747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with 'ovr' multiclass: 0.8947368421052632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6) C Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "gWShc0kVHBRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "              'penalty': ['l1', 'l2']}\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNx2LHcTG9hZ",
        "outputId": "c06319c5-7ee9-47c9-bf97-4af68233d6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
            "Best Accuracy: 0.9731225296442687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7) Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "l2fQeEoeHXSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Create a StratifiedKFold object\n",
        "stratified_kfold = StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(model, X, y, cv=stratified_kfold)\n",
        "\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy:\", scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc5bfBkmHVGh",
        "outputId": "bace9bee-5590-489c-9370-49e9c26c9678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8) Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "zbss26KWHoI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('california_housing.csv')\n",
        "\n",
        "# Assuming the last column is the target variable\n",
        "X = data.iloc[:, :-1]  # Features\n",
        "y = data.iloc[:, -1]   # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vty2QCQgLb0C",
        "outputId": "40535954-7145-4bae-e46d-e3f69f7c1856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.015037593984962405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9) Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "0IAlTFiFMbnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the parameter distribution for RandomizedSearchCV\n",
        "param_dist = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "              'penalty': ['l1', 'l2'],\n",
        "              'solver': ['liblinear', 'saga']}\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Create a RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=5, random_state=1)\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Accuracy:\", random_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHXy-_kfOYvY",
        "outputId": "74be58c2-ccb4-4367-ee4f-7c1954971143"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 1}\n",
            "Best Accuracy: 0.9731225296442687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10) Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "7tzNvM1YM8KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Create a OneVsOneClassifier using the Logistic Regression model\n",
        "ovo_classifier = OneVsOneClassifier(model)\n",
        "\n",
        "# Train the OvO classifier\n",
        "ovo_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ovo_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with One-vs-One Logistic Regression:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjqswJHTOMfM",
        "outputId": "a64b0afd-7b0f-45cb-d637-1d348920b28e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with One-vs-One Logistic Regression: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11) Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."
      ],
      "metadata": {
        "id": "S97usZIiOdEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix for Logistic Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wNZ4-YEhOnFW",
        "outputId": "55fc9387-58c1-400a-e3b5-43fe933c9698"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 12) Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,Recall, and F1-Score."
      ],
      "metadata": {
        "id": "nRPW4_i0OxEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall, and F1-Score.\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# have already trained your model and have y_test and y_pred\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multi-class\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"F1-Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQjEuS07PBTT",
        "outputId": "6637b396-8bbf-4d64-ac32-c3a83229bf84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9763157894736842\n",
            "Recall: 0.9736842105263158\n",
            "F1-Score: 0.9739522830846216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 13) Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "XVLdWAZ8PIOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Create an imbalanced dataset\n",
        "X = X[:100]  # Keep only the first two classes\n",
        "y = y[:100]\n",
        "y[:50] = 0  # Make the first 50 samples belong to class 0\n",
        "y[50:] = 1  # Make the remaining 50 samples belong to class 1\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Calculate the class weights (inverse of the class frequencies)\n",
        "from collections import Counter\n",
        "counter = Counter(y_train)\n",
        "class_weights = {i: 1.0 / counter[i] for i in counter}\n",
        "\n",
        "# Create a Logistic Regression model with class weights\n",
        "model = LogisticRegression(class_weight=class_weights, max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQVgvv2JPclj",
        "outputId": "9a0ca312-7b8f-4d25-8a00-19a178b99fdc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 14) Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance."
      ],
      "metadata": {
        "id": "j8cQdGDoPlie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Titanic dataset\n",
        "titanic_data = sns.load_dataset('titanic')\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "target = 'survived'\n",
        "\n",
        "# Create a copy of the data for preprocessing\n",
        "data = titanic_data[features + [target]].copy()\n",
        "\n",
        "# Convert categorical features to numerical using one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['sex', 'embarked'], dummy_na=True)\n",
        "\n",
        "# Handle missing values using SimpleImputer (e.g., replace with the mean)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data['age'] = imputer.fit_transform(data[['age']])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = data.drop(target, axis=1)\n",
        "y = data[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5KmDvH9P3TQ",
        "outputId": "745f120a-6872-41f8-db0d-48ae5a4d0cb6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8071748878923767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 15) Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "-Es8poOSRjzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model without scaling\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set without scaling\n",
        "y_pred_no_scaling = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model without scaling\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(\"Accuracy without scaling:\", accuracy_no_scaling)\n",
        "\n",
        "# Apply feature scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the model with scaling\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set with scaling\n",
        "y_pred_scaling = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the accuracy of the model with scaling\n",
        "accuracy_scaling = accuracy_score(y_test, y_pred_scaling)\n",
        "print(\"Accuracy with scaling:\", accuracy_scaling)\n",
        "\n",
        "# Compare the results\n",
        "print(\"Difference in accuracy:\", accuracy_scaling - accuracy_no_scaling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt4sbRVCRvV_",
        "outputId": "025c167b-b755-4d3e-8120-ca59879b04f6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.9777777777777777\n",
            "Accuracy with scaling: 0.9555555555555556\n",
            "Difference in accuracy: -0.022222222222222143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16) Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "RGnEk8ibR27M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_probs = model.predict_proba(X_test)[:, 1]  # Probability of class = 1\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNDvZT0_SWZn",
        "outputId": "eb54ebdf-ac3d-48e4-df5a-c2cac2362c0b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 17) Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy."
      ],
      "metadata": {
        "id": "PM_aATAUS55n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the breast_cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Create a Logistic Regression model with a custom learning rate (C=0.5)\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with custom learning rate (C=0.5):\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q4iH1LHTCzL",
        "outputId": "fb3bdd43-269f-4d9d-ddc4-c6e0c1ec4289"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with custom learning rate (C=0.5): 0.9370629370629371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 18) Write a Python program to train Logistic Regression and identify important features based on model coefficients."
      ],
      "metadata": {
        "id": "S3JJttftTOBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Create and train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get the coefficients of the model\n",
        "coefficients = model.coef_\n",
        "\n",
        "# Create a DataFrame to store the feature names and their corresponding coefficients\n",
        "feature_importance = pd.DataFrame({'Feature': iris.feature_names, 'Coefficient': coefficients[0]})\n",
        "\n",
        "# Sort the features by the absolute value of their coefficients (importance)\n",
        "feature_importance['Abs_Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
        "feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "# Print the important features\n",
        "print(\"Important Features based on Coefficients:\")\n",
        "print(feature_importance[['Feature', 'Coefficient']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K032n64OTKv7",
        "outputId": "7da1ede6-09c7-4a5e-ad3a-89ec14c99e52"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Important Features based on Coefficients:\n",
            "             Feature  Coefficient\n",
            "2  petal length (cm)    -2.304520\n",
            "3   petal width (cm)    -0.950636\n",
            "1   sepal width (cm)     0.804470\n",
            "0  sepal length (cm)    -0.430520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 19) Write a Python program to train Logistic Regression and evaluate its performance using Cohens Kappa Score."
      ],
      "metadata": {
        "id": "7scTf5FUT9lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Cohen's Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL-Z8Z5hT3Mo",
        "outputId": "95bf4a9f-bf12-4278-d850-4723ad4a7757"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.9555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 20) Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."
      ],
      "metadata": {
        "id": "aXOpRbTpUgNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset (Breast Cancer dataset is a good example for binary classification)\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision, recall, and thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "# Calculate AUC (Area Under the Curve) for Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.plot(recall, precision, label=f'Precision-Recall curve (AUC = {pr_auc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Logistic Regression')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "f0__I9tnUuXs",
        "outputId": "46245a10-674c-4e7c-ae33-69d753c9e3a4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW0dJREFUeJzt3XlYVGX/P/D3MDAz7IjsSCBupKEmKl9cQo1EMcuecl+Q3LdMMtNcME3JSsLS1Mots8QtH0vFFLNcUHMtcwkUxQ1Qk13WuX9/+OM8jgwIODDieb+uay6dM/e5z+ec2d6cc58zCiGEABEREZGMmBi7ACIiIqKaxgBEREREssMARERERLLDAERERESywwBEREREssMARERERLLDAERERESywwBEREREssMARERERLLDAERPpKFDh8LLy6tS8+zbtw8KhQL79u2rlppqu06dOqFTp07S/cuXL0OhUGD16tVGq8nYsrOzMXz4cLi4uEChUODtt982dkkGZ+j3xerVq6FQKHD58mWD9EfA7NmzoVAojF2G7DAAEYD/faiV3DQaDRo3bozx48cjNTXV2OU98UrCRMnNxMQE9vb26N69O+Lj441dnkGkpqZi8uTJ8PHxgYWFBSwtLeHn54cPP/wQ6enpxi6vSubPn4/Vq1djzJgxWLt2LQYPHlyty/Py8sLLL79crcswlPnz52Pr1q3VuoyHP3dMTU3h7u6OoUOH4vr169W6bCIFfwuMgPsfRGFhYZgzZw7q16+PvLw8HDhwAGvXroWnpyfOnDkDCwuLGqunsLAQWq0WarW6wvNotVoUFBRApVLBxKRms/3ly5dRv3599O/fHyEhISguLsY///yDL7/8Evfu3cMff/wBX1/fGq3pYSV7f0r2BJTUvGrVKgwdOrTcef/44w+EhIQgOzsbgwYNgp+fHwDg2LFjWL9+Pdq1a4dffvmlGquvHv/3f/8HU1NTHDhwoEaW5+Xlheeeew4///xzjSwPqPr7wsrKCm+88UapPYTFxcUoLCyEWq1+7L0W+j53Dh8+jNWrV8PLywtnzpyBRqN5rGXUBkVFRSgqKpLFuj5JTI1dAD1ZunfvjtatWwMAhg8fjrp16yIqKgr//e9/0b9/f73z5OTkwNLS0qB1mJmZVXoeExMTo3+AtGrVCoMGDZLud+zYEd27d8fSpUvx5ZdfGrGyqktPT8drr70GpVKJkydPwsfHR+fxefPm4euvvzbIsqrjtVSetLQ0NG3a1GD9FRUVQavVQqVSGazPx2Xo94VSqYRSqTRYf0Dpzx0HBwcsWLAA27ZtQ58+fQy6rPIIIZCXlwdzc/MaWyYAmJqawtSUX8c1jYfAqFxdunQBACQlJQG4PzbHysoKFy9eREhICKytrTFw4EAA9//SjI6ORrNmzaDRaODs7IxRo0bh7t27pfrduXMnAgMDYW1tDRsbG7Rp0wbff/+99Li+MUDr16+Hn5+fNI+vry8WLVokPV7WWIeNGzfCz88P5ubmcHBwwKBBg0rtXi9Zr+vXr6NXr16wsrKCo6MjJk+ejOLi4ipvv44dOwIALl68qDM9PT0db7/9Njw8PKBWq9GwYUMsWLAAWq1Wp51Wq8WiRYvg6+sLjUYDR0dHdOvWDceOHZParFq1Cl26dIGTkxPUajWaNm2KpUuXVrnmhy1fvhzXr19HVFRUqfADAM7OzpgxY4Z0X6FQYPbs2aXaeXl56expKjn88dtvv2Hs2LFwcnJCvXr1sGnTJmm6vloUCgXOnDkjTTt//jzeeOMN2NvbQ6PRoHXr1ti2bVu561TyWklKSsL27dulQzAl41rS0tIwbNgwODs7Q6PRoEWLFlizZo1OHyWHPT/99FNER0ejQYMGUKvVOHv2bLnLfpSioiLMnTtX6s/Lywvvv/8+8vPzddpptVrMnj0bbm5usLCwQOfOnXH27NlS21nf+yIhIQGvv/46XFxcoNFoUK9ePfTr1w8ZGRkA7j+HOTk5WLNmjbRtSvosawzQo97TlVHW+6aiz/Wff/6JwMBAmJubo169evjwww+xatWqUnWXHJLctWsXWrduDXNzcyxfvhxAxd+jj/pcKiwsxAcffIBGjRpBo9Ggbt266NChA3bv3i210TcGqKKvg5J1OHDgANq2bQuNRgNvb298++23ldji8sTISeUq+QCqW7euNK2oqAjBwcHo0KEDPv30U+nQ2KhRo6Rd2m+99RaSkpKwePFinDx5EgcPHpT26qxevRpvvvkmmjVrhmnTpsHOzg4nT55EbGwsBgwYoLeO3bt3o3///njxxRexYMECAMC5c+dw8OBBTJw4scz6S+pp06YNIiMjkZqaikWLFuHgwYM4efIk7OzspLbFxcUIDg6Gv78/Pv30U+zZswcLFy5EgwYNMGbMmCptv5IP2zp16kjTcnNzERgYiOvXr2PUqFF45plncOjQIUybNg03b95EdHS01HbYsGFYvXo1unfvjuHDh6OoqAj79+/H4cOHpb+Yly5dimbNmuGVV16BqakpfvrpJ4wdOxZarRbjxo2rUt0P2rZtG8zNzfHGG288dl/6jB07Fo6Ojpg1axZycnLQo0cPWFlZYcOGDQgMDNRpGxMTg2bNmuG5554DAPz9999o37493N3dMXXqVFhaWmLDhg3o1asXNm/ejNdee03vMp999lmsXbsWkyZNQr169fDOO+8AABwdHXHv3j106tQJiYmJGD9+POrXr4+NGzdi6NChSE9PL/V6W7VqFfLy8jBy5Eio1WrY29s/1vYYPnw41qxZgzfeeAPvvPMOjhw5gsjISJw7dw4//vij1G7atGn4+OOP0bNnTwQHB+P06dMIDg5GXl5euf0XFBQgODgY+fn5mDBhAlxcXHD9+nX8/PPPSE9Ph62tLdauXYvhw4ejbdu2GDlyJACgQYMGZfZZlfd0efS9byr6XF+/fh2dO3eGQqHAtGnTYGlpiW+++abMw+kXLlxA//79MWrUKIwYMQJNmjSp8Hu0Ip9Ls2fPRmRkpLQ9MzMzcezYMZw4cQIvvfRSmdugoq8DAEhMTMQbb7yBYcOGITQ0FCtXrsTQoUPh5+eHZs2aVXr7y4YgEkKsWrVKABB79uwRt27dElevXhXr168XdevWFebm5uLatWtCCCFCQ0MFADF16lSd+ffv3y8AiHXr1ulMj42N1Zmenp4urK2thb+/v7h3755OW61WK/0/NDRUeHp6SvcnTpwobGxsRFFRUZnr8OuvvwoA4tdffxVCCFFQUCCcnJzEc889p7Osn3/+WQAQs2bN0lkeADFnzhydPp9//nnh5+dX5jJLJCUlCQDigw8+ELdu3RIpKSli//79ok2bNgKA2Lhxo9R27ty5wtLSUvzzzz86fUydOlUolUqRnJwshBBi7969AoB46623Si3vwW2Vm5tb6vHg4GDh7e2tMy0wMFAEBgaWqnnVqlXlrludOnVEixYtym3zIAAiIiKi1HRPT08RGhoq3S95zXXo0KHU89q/f3/h5OSkM/3mzZvCxMRE5zl68cUXha+vr8jLy5OmabVa0a5dO9GoUaNH1urp6Sl69OihMy06OloAEN999500raCgQAQEBAgrKyuRmZkphPjf9rOxsRFpaWmPXFZZy3vQqVOnBAAxfPhwnemTJ08WAMTevXuFEEKkpKQIU1NT0atXL512s2fPFgB0tvPD74uTJ0+Wek3qY2lpqdNPiZLnLSkpSQhR8fe0Pvo+dzZt2iQcHR2FWq0WV69eldpW9LmeMGGCUCgU4uTJk9K0O3fuCHt7e526hbj/fAAQsbGxOnVV9D1akc+lFi1alPucCyFERESEePDruKKvgwfX4ffff5empaWlCbVaLd55551ylyt3PARGOoKCguDo6AgPDw/069cPVlZW+PHHH+Hu7q7T7uE9Ihs3boStrS1eeukl3L59W7r5+fnBysoKv/76K4D7fzFlZWVh6tSppcYllDeg0s7ODjk5OTq7jR/l2LFjSEtLw9ixY3WW1aNHD/j4+GD79u2l5hk9erTO/Y4dO+LSpUsVXmZERAQcHR3h4uKCjh074ty5c1i4cKHO3pONGzeiY8eOqFOnjs62CgoKQnFxMX7//XcAwObNm6FQKBAREVFqOQ9uqwfHK2RkZOD27dsIDAzEpUuXpEMajyMzMxPW1taP3U9ZRowYUWpMSd++fZGWlqZz2GbTpk3QarXo27cvAODff//F3r170adPH2RlZUnb8c6dOwgODkZCQkKVziTasWMHXFxcdMa8mZmZ4a233kJ2dnapQ3Ovv/46HB0dK72cspYNAOHh4TrTS/ZQlbxm4+LiUFRUhLFjx+q0mzBhwiOXYWtrCwDYtWsXcnNzH7vmqr6nH/Tg584bb7wBS0tLbNu2DfXq1QNQuec6NjYWAQEBaNmypdS/vb29dKj+YfXr10dwcLDOtIq+RyvyuWRnZ4e///4bCQkJFdoWQMVfByWaNm0qHTYE7u/JbNKkSaU+u+SIh8BIx5IlS9C4cWOYmprC2dkZTZo0KXXmiKmpqfTBVCIhIQEZGRlwcnLS229aWhqA/x1SKzmEUVFjx47Fhg0b0L17d7i7u6Nr167o06cPunXrVuY8V65cAQA0adKk1GM+Pj6lzvwpGWPzoDp16uiMYbp165bOmCArKytYWVlJ90eOHInevXsjLy8Pe/fuxeeff15qDFFCQgL+/PPPMr80H9xWbm5ujzykcvDgQURERCA+Pr7UF1pGRob0hVdVNjY2yMrKeqw+ylO/fv1S07p16wZbW1vExMTgxRdfBHD/8FfLli3RuHFjAPd3+wshMHPmTMycOVNv32lpaaXC+6NcuXIFjRo1KvW6f/bZZ6XHH1V/VV25cgUmJiZo2LChznQXFxfY2dlJyy759+F29vb2OoeN9Klfvz7Cw8MRFRWFdevWoWPHjnjllVcwaNCgKr1WqvqeflDJ505GRgZWrlyJ33//XeeQVWWe6ytXriAgIKDU4w9vqxL6nr+Kvkcr8rk0Z84cvPrqq2jcuDGee+45dOvWDYMHD0bz5s3L3B4VfR2UeOaZZ0r18fBnF5XGAEQ62rZtK40tKYtarS715aDVauHk5IR169bpnedx/0J2cnLCqVOnsGvXLuzcuRM7d+7EqlWrMGTIkFKDU6uqIme2tGnTRufDJyIiQmfAb6NGjRAUFAQAePnll6FUKjF16lR07txZ2q5arRYvvfQSpkyZoncZJV/wFXHx4kW8+OKL8PHxQVRUFDw8PKBSqbBjxw589tlnpQZsVoWPjw9OnTolnUpdVWUNJtd3xo1arUavXr3w448/4ssvv0RqaioOHjyI+fPnS21K1m3y5Mml/oIvUdaXniFVxxlD1X1RvIULF2Lo0KH473//i19++QVvvfUWIiMjcfjw4VJ/3NSEBz93evXqhQ4dOmDAgAG4cOECrKysqvW51vf8VfQ9WpHPpRdeeAEXL16UtvU333yDzz77DMuWLcPw4cPLra2ir4OyPrsEr3JTLgYgMogGDRpgz549aN++fblfCCUDKc+cOVPpDyyVSoWePXuiZ8+e0Gq1GDt2LJYvX46ZM2fq7cvT0xPA/UGOJWezlbhw4YL0eGWsW7cO9+7dk+57e3uX23769On4+uuvMWPGDMTGxgK4vw2ys7OloFSWBg0aYNeuXfj333/L3Av0008/IT8/H9u2bdP5K7DkkKMh9OzZE/Hx8di8eXOZl0J4UJ06dUpdGLGgoAA3b96s1HL79u2LNWvWIC4uDufOnYMQQjr8Bfxv25uZmT1yW1aGp6cn/vzzT2i1Wp2gf/78eenx6uLp6QmtVouEhARpjxNw/yKU6enp0rJL/k1MTNTZg3Hnzp0K/9Xv6+sLX19fzJgxA4cOHUL79u2xbNkyfPjhhwAq/uX7OO9pfZRKJSIjI9G5c2csXrwYU6dOrdRz7enpicTExFLT9U0rS0Xfo0DFPpfs7e0RFhaGsLAwZGdn44UXXsDs2bPLDEAVfR3Q4+EYIDKIPn36oLi4GHPnzi31WFFRkfSF2LVrV1hbWyMyMrLU2Srl/bVy584dnfsmJibSLuSHTwst0bp1azg5OWHZsmU6bXbu3Ilz586hR48eFVq3B7Vv3x5BQUHS7VEByM7ODqNGjcKuXbtw6tQpAPe3VXx8PHbt2lWqfXp6OoqKigDcH1sihMAHH3xQql3Jtir5y+/BbZeRkYFVq1ZVet3KMnr0aLi6uuKdd97BP//8U+rxtLQ06UsTuP/lUTJGosRXX31V6csJBAUFwd7eHjExMYiJiUHbtm11vuydnJzQqVMnLF++XG+4unXrVqWWVyIkJAQpKSmIiYmRphUVFeGLL76AlZVVqTPTDCkkJAQAdM4EBICoqCgAkF6zL774IkxNTUtd7mDx4sWPXEZmZqb0Givh6+sLExMTnfeJpaVlha7wXdX3dHk6deqEtm3bIjo6Gnl5eZV6roODgxEfHy+934D7Y4jK2jutT0XfoxX5XHq4jZWVFRo2bFjm5xZQ8dcBPR7uASKDCAwMxKhRoxAZGYlTp06ha9euMDMzQ0JCAjZu3IhFixbhjTfegI2NDT777DMMHz4cbdq0wYABA1CnTh2cPn0aubm5ZR7OGj58OP7991906dIF9erVw5UrV/DFF1+gZcuWOn8hPcjMzAwLFixAWFgYAgMD0b9/f+k0eC8vL0yaNKk6N4lk4sSJiI6OxkcffYT169fj3XffxbZt2/Dyyy9Lp6rm5OTgr7/+wqZNm3D58mU4ODigc+fOGDx4MD7//HMkJCSgW7du0Gq12L9/Pzp37ozx48eja9eu0l+go0aNQnZ2Nr7++ms4OTlVeo9LWerUqYMff/wRISEhaNmypc6VoE+cOIEffvhBZ8zF8OHDMXr0aLz++ut46aWXcPr0aezatQsODg6VWq6ZmRn+85//YP369cjJycGnn35aqs2SJUvQoUMH+Pr6YsSIEfD29kZqairi4+Nx7do1nD59utLrO3LkSCxfvhxDhw7F8ePH4eXlhU2bNuHgwYOIjo5+7AHhiYmJOoGxxPPPP48ePXogNDQUX331FdLT0xEYGIijR49izZo16NWrFzp37gzg/rWXJk6ciIULF+KVV15Bt27dcPr0aezcuRMODg7l7r3Zu3cvxo8fj969e6Nx48YoKirC2rVroVQq8frrr0vt/Pz8sGfPHkRFRcHNzQ3169eHv79/qf6q+p5+lHfffRe9e/fG6tWrMXr06Ao/11OmTMF3332Hl156CRMmTJBOg3/mmWfw77//VmjPVkXfoxX5XGratCk6deoEPz8/2Nvb49ixY9i0aRPGjx9f5vJbtGhRodcBPSajnX9GT5SS01H/+OOPctuFhoYKS0vLMh//6quvhJ+fnzA3NxfW1tbC19dXTJkyRdy4cUOn3bZt20S7du2Eubm5sLGxEW3bthU//PCDznIePA1+06ZNomvXrsLJyUmoVCrxzDPPiFGjRombN29KbR4+3bdETEyMeP7554VarRb29vZi4MCB0mn9j1qvh09PLUvJKdGffPKJ3seHDh0qlEqlSExMFEIIkZWVJaZNmyYaNmwoVCqVcHBwEO3atROffvqpKCgokOYrKioSn3zyifDx8REqlUo4OjqK7t27i+PHj+tsy+bNmwuNRiO8vLzEggULxMqVK0ud8lvV0+BL3LhxQ0yaNEk0btxYaDQaYWFhIfz8/MS8efNERkaG1K64uFi89957wsHBQVhYWIjg4GCRmJhY5mnw5b3mdu/eLQAIhUKhc0r0gy5evCiGDBkiXFxchJmZmXB3dxcvv/yy2LRp0yPXqazT0lNTU0VYWJhwcHAQKpVK+Pr6ltpOj3rOy1oeAL23YcOGCSGEKCwsFB988IGoX7++MDMzEx4eHmLatGk6p38Lcf+1MXPmTOHi4iLMzc1Fly5dxLlz50TdunXF6NGjpXYPvy8uXbok3nzzTdGgQQOh0WiEvb296Ny5s9izZ49O/+fPnxcvvPCCMDc31zm1/uHT4Es86j2tT3mvgeLiYtGgQQPRoEED6TTzij7XJ0+eFB07dhRqtVrUq1dPREZGis8//1wAECkpKTrPR1mnqFfkPVqRz6UPP/xQtG3bVtjZ2Qlzc3Ph4+Mj5s2bp/M+1/c5U9HXQVnr8PD7nUrjb4ERET0l0tPTUadOHXz44YeYPn26sct5orz99ttYvnw5srOzDf5THlQ7cQwQEVEt9OBg/BIlY0ZKfvhWrh7eNnfu3MHatWvRoUMHhh+ScAwQEVEtFBMTg9WrVyMkJARWVlY4cOAAfvjhB3Tt2hXt27c3dnlGFRAQgE6dOuHZZ59FamoqVqxYgczMzDKvIUTyxABERFQLNW/eHKampvj444+RmZkpDYzWN8BabkJCQrBp0yZ89dVXUCgUaNWqFVasWIEXXnjB2KXRE4RjgIiIiEh2OAaIiIiIZIcBiIiIiGSHY4D00Gq1uHHjBqytrav9N3mIiIjIMIQQyMrKgpubW6nfrHwYA5AeN27cgIeHh7HLICIioiq4evXqI3/YlwFIj5JL3V+9ehU2NjZGroaIiIgqIjMzEx4eHhX6yRoGID1KDnvZ2NgwABEREdUyFRm+wkHQREREJDsMQERERCQ7DEBEREQkOwxAREREJDsMQERERCQ7DEBEREQkOwxAREREJDsMQERERCQ7DEBEREQkOwxAREREJDtGDUC///47evbsCTc3NygUCmzduvWR8+zbtw+tWrWCWq1Gw4YNsXr16lJtlixZAi8vL2g0Gvj7++Po0aOGL56IiIhqLaMGoJycHLRo0QJLliypUPukpCT06NEDnTt3xqlTp/D2229j+PDh2LVrl9QmJiYG4eHhiIiIwIkTJ9CiRQsEBwcjLS2tulaDiIiIahmFEEIYuwjg/g+X/fjjj+jVq1eZbd577z1s374dZ86ckab169cP6enpiI2NBQD4+/ujTZs2WLx4MQBAq9XCw8MDEyZMwNSpUytUS2ZmJmxtbZGRkWHQH0PNzCtE5r1Cg/VHRETyYq02g62FmbHLeGJV5vu7Vv0afHx8PIKCgnSmBQcH4+233wYAFBQU4Pjx45g2bZr0uImJCYKCghAfH19mv/n5+cjPz5fuZ2ZmGrbw/++7w1fwceyFaumbiIiefqYmCvww8v/Qxsve2KXUerUqAKWkpMDZ2VlnmrOzMzIzM3Hv3j3cvXsXxcXFetucP3++zH4jIyPxwQcfVEvNDzI1UUBtynHnRERUeYXFWhRpBc7eyGQAMoBaFYCqy7Rp0xAeHi7dz8zMhIeHh8GXM/KFBhj5QgOD90tERE+/cd+fwPY/bxq7jKdGrQpALi4uSE1N1ZmWmpoKGxsbmJubQ6lUQqlU6m3j4uJSZr9qtRpqtbpaaiYiIqInT606HhMQEIC4uDidabt370ZAQAAAQKVSwc/PT6eNVqtFXFyc1IaIiIjIqAEoOzsbp06dwqlTpwDcP8391KlTSE5OBnD/0NSQIUOk9qNHj8alS5cwZcoUnD9/Hl9++SU2bNiASZMmSW3Cw8Px9ddfY82aNTh37hzGjBmDnJwchIWF1ei6ERER0ZPLqIfAjh07hs6dO0v3S8bhhIaGYvXq1bh586YUhgCgfv362L59OyZNmoRFixahXr16+OabbxAcHCy16du3L27duoVZs2YhJSUFLVu2RGxsbKmB0URERCRfT8x1gJ4k1XUdICIioqoqGQT9wSvNENrOy9jlPJEq8/1dq8YAERERERlCrToLjIiISO5WHUzCttM3UFishZnSBNN7PItWz9Qxdlm1DgMQERFRLeBodf9yLZfv5OLynVxp+ubj1xiAqoABiIiIqBaYHNwEbbzsoRUCZkoTxJ65ia2nbkDLkbxVwgBERERUC1ipTdGjuat0PyE1y4jV1H4cBE1ERESywwBEREREssMARERERLLDAERERERVUlSsRVZeIWrjNZU5CJqIiOgpJIRAQbEWeQVa5BYW4V5BMXILipFXeP/fe4XF0rT7/y/CvcKH2vz/xx78//15ipBXqEVBsRYA4F/fHjGjatePjjMAERER1WJ7zqXi/JeZesNKcQ2dI38k6d8aWY4hMQARERHVQg7W9y+MeCsrH7ey8stta6ZUQGOmhIVKCXMzJcxVpjA3M4GFyhTm/3+ahUr5UJv7t/v3TR/4v1Ka515hMV5c+FtNrK7BMQARERHVQq+3qoc6FirkFxX//wBjCnOVCczNTO8HFdX/goqZsnqG/N7OLj94PckYgIiIiGohlakJuj3nYuwyai2eBUZERESywwBEREREssMARERERAYjhKgV1wXiGCAiIiJ6bO0/2ousvEJk5xfB29EKP0/oAI2Z0thllYl7gIiIiKhKrNSmsNbc35dyPf0eMvOKoBVAYlo2rtzJNXJ15eMeICIiIqoSjZkSsW+/gEu3smGtMYOV2hS9lx3C3dxCY5f2SAxAREREVGXuduZwtzOX7itNFEaspuJ4CIyIiIhkhwGIiIiIZIcBiIiIiGSHY4CIiIjI4LLzC3H131yk5xYi/V4B7uYWIiO3AOm5hVAogIH+nqhjqTJafQxAREREZHCvL40v93GFQoFxnRvWUDWlMQARERGRwTSvZ4e959MAABozE9iZq2BnYQZbczPYWZjh4q0cJKZlIye/yKh1MgARERGRwawIbY1bWfmwMTfTeyXoOT+dRWJathEq08UARERERAajUCjgZKMxdhmPxLPAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2jB6AlixZAi8vL2g0Gvj7++Po0aNlti0sLMScOXPQoEEDaDQatGjRArGxsTptZs+eDYVCoXPz8fGp7tUgIiKiWsSoASgmJgbh4eGIiIjAiRMn0KJFCwQHByMtLU1v+xkzZmD58uX44osvcPbsWYwePRqvvfYaTp48qdOuWbNmuHnzpnQ7cOBATawOERER1RJGDUBRUVEYMWIEwsLC0LRpUyxbtgwWFhZYuXKl3vZr167F+++/j5CQEHh7e2PMmDEICQnBwoULddqZmprCxcVFujk4ONTE6hAREVEtYbQAVFBQgOPHjyMoKOh/xZiYICgoCPHx+n8/JD8/HxqN7sWVzM3NS+3hSUhIgJubG7y9vTFw4EAkJycbfgWIiIio1jJaALp9+zaKi4vh7OysM93Z2RkpKSl65wkODkZUVBQSEhKg1Wqxe/dubNmyBTdv3pTa+Pv7Y/Xq1YiNjcXSpUuRlJSEjh07Iisrq8xa8vPzkZmZqXMjIiKip5fRB0FXxqJFi9CoUSP4+PhApVJh/PjxCAsLg4nJ/1aje/fu6N27N5o3b47g4GDs2LED6enp2LBhQ5n9RkZGwtbWVrp5eHjUxOoQERGRkRgtADk4OECpVCI1NVVnempqKlxcXPTO4+joiK1btyInJwdXrlzB+fPnYWVlBW9v7zKXY2dnh8aNGyMxMbHMNtOmTUNGRoZ0u3r1atVWioiIiGoFowUglUoFPz8/xMXFSdO0Wi3i4uIQEBBQ7rwajQbu7u4oKirC5s2b8eqrr5bZNjs7GxcvXoSrq2uZbdRqNWxsbHRuRERE9PQy6iGw8PBwfP3111izZg3OnTuHMWPGICcnB2FhYQCAIUOGYNq0aVL7I0eOYMuWLbh06RL279+Pbt26QavVYsqUKVKbyZMn47fffsPly5dx6NAhvPbaa1Aqlejfv3+Nrx8RERE9mUyNufC+ffvi1q1bmDVrFlJSUtCyZUvExsZKA6OTk5N1xvfk5eVhxowZuHTpEqysrBASEoK1a9fCzs5OanPt2jX0798fd+7cgaOjIzp06IDDhw/D0dGxplePiIiInlAKIYQwdhFPmszMTNja2iIjI4OHw4iIiAxozk9nsfJgEsZ2aoAp3Qz7Sw2V+f6uVWeBERERERkCAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJjtED0JIlS+Dl5QWNRgN/f38cPXq0zLaFhYWYM2cOGjRoAI1GgxYtWiA2Nvax+iQiIiL5MWoAiomJQXh4OCIiInDixAm0aNECwcHBSEtL09t+xowZWL58Ob744gucPXsWo0ePxmuvvYaTJ09WuU8iIiKSH6MGoKioKIwYMQJhYWFo2rQpli1bBgsLC6xcuVJv+7Vr1+L9999HSEgIvL29MWbMGISEhGDhwoVV7pOIiIjkx2gBqKCgAMePH0dQUND/ijExQVBQEOLj4/XOk5+fD41GozPN3NwcBw4cqHKfJf1mZmbq3IiIiOjpZbQAdPv2bRQXF8PZ2VlnurOzM1JSUvTOExwcjKioKCQkJECr1WL37t3YsmULbt68WeU+ASAyMhK2trbSzcPD4zHXjoiIiJ5kRh8EXRmLFi1Co0aN4OPjA5VKhfHjxyMsLAwmJo+3GtOmTUNGRoZ0u3r1qoEqJiIioieR0QKQg4MDlEolUlNTdaanpqbCxcVF7zyOjo7YunUrcnJycOXKFZw/fx5WVlbw9vaucp8AoFarYWNjo3MjIiKip5fRApBKpYKfnx/i4uKkaVqtFnFxcQgICCh3Xo1GA3d3dxQVFWHz5s149dVXH7tPIiIikg9TYy48PDwcoaGhaN26Ndq2bYvo6Gjk5OQgLCwMADBkyBC4u7sjMjISAHDkyBFcv34dLVu2xPXr1zF79mxotVpMmTKlwn0SERERGTUA9e3bF7du3cKsWbOQkpKCli1bIjY2VhrEnJycrDO+Jy8vDzNmzMClS5dgZWWFkJAQrF27FnZ2dhXuk4iIiEghhBDGLuJJk5mZCVtbW2RkZHA8EBERkQHN+eksVh5MwthODTClm49B+67M93etOguMiIiIyBAYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHaMHoCWLFkCLy8vaDQa+Pv74+jRo+W2j46ORpMmTWBubg4PDw9MmjQJeXl50uOzZ8+GQqHQufn4+FT3ahAREVEtYmrMhcfExCA8PBzLli2Dv78/oqOjERwcjAsXLsDJyalU+++//x5Tp07FypUr0a5dO/zzzz8YOnQoFAoFoqKipHbNmjXDnj17pPumpkZdTSIiInrCGHUPUFRUFEaMGIGwsDA0bdoUy5Ytg4WFBVauXKm3/aFDh9C+fXsMGDAAXl5e6Nq1K/r3719qr5GpqSlcXFykm4ODQ02sDhEREdUSRgtABQUFOH78OIKCgv5XjIkJgoKCEB8fr3eedu3a4fjx41LguXTpEnbs2IGQkBCddgkJCXBzc4O3tzcGDhyI5OTk6lsRIiIiqnWMdmzo9u3bKC4uhrOzs850Z2dnnD9/Xu88AwYMwO3bt9GhQwcIIVBUVITRo0fj/fffl9r4+/tj9erVaNKkCW7evIkPPvgAHTt2xJkzZ2Btba233/z8fOTn50v3MzMzDbCGRERE9KQy+iDoyti3bx/mz5+PL7/8EidOnMCWLVuwfft2zJ07V2rTvXt39O7dG82bN0dwcDB27NiB9PR0bNiwocx+IyMjYWtrK908PDxqYnWIiIjISIy2B8jBwQFKpRKpqak601NTU+Hi4qJ3npkzZ2Lw4MEYPnw4AMDX1xc5OTkYOXIkpk+fDhOT0nnOzs4OjRs3RmJiYpm1TJs2DeHh4dL9zMxMhiAiIqKnmNH2AKlUKvj5+SEuLk6aptVqERcXh4CAAL3z5Obmlgo5SqUSACCE0DtPdnY2Ll68CFdX1zJrUavVsLGx0bkRERHR08uo54eHh4cjNDQUrVu3Rtu2bREdHY2cnByEhYUBAIYMGQJ3d3dERkYCAHr27ImoqCg8//zz8Pf3R2JiImbOnImePXtKQWjy5Mno2bMnPD09cePGDURERECpVKJ///5GW08iIiJ6slQpABUXF2P16tWIi4tDWloatFqtzuN79+6tUD99+/bFrVu3MGvWLKSkpKBly5aIjY2VBkYnJyfr7PGZMWMGFAoFZsyYgevXr8PR0RE9e/bEvHnzpDbXrl1D//79cefOHTg6OqJDhw44fPgwHB0dq7KqRERE9BRSiLKOHZVj/PjxWL16NXr06AFXV1coFAqdxz/77DODFWgMmZmZsLW1RUZGBg+HERERGdCcn85i5cEkjO3UAFO6GfaXGirz/V2lPUDr16/Hhg0bSl1/h4iIiKg2qNIgaJVKhYYNGxq6FiIiIqIaUaUA9M4772DRokVlnnlFRERE9CSr0iGwAwcO4Ndff8XOnTvRrFkzmJmZ6Ty+ZcsWgxRHREREVB2qFIDs7Ozw2muvGboWIiIiohpRpQC0atUqQ9dBREREVGMe60KIt27dwoULFwAATZo04bV2iIiIqFao0iDonJwcvPnmm3B1dcULL7yAF154AW5ubhg2bBhyc3MNXSMRERGRQVUpAIWHh+O3337DTz/9hPT0dKSnp+O///0vfvvtN7zzzjuGrpGIiIjIoKp0CGzz5s3YtGkTOnXqJE0LCQmBubk5+vTpg6VLlxqqPiIiIiKDq9IeoNzcXOn3uh7k5OTEQ2BERET0xKtSAAoICEBERATy8vKkaffu3cMHH3yAgIAAgxVHREREVB2qdAhs0aJFCA4ORr169dCiRQsAwOnTp6HRaLBr1y6DFkhERERkaFUKQM899xwSEhKwbt06nD9/HgDQv39/DBw4EObm5gYtkIiIiMjQqnwdIAsLC4wYMcKQtRARERHViAoHoG3btqF79+4wMzPDtm3bym37yiuvPHZhRERERNWlwgGoV69eSElJgZOTE3r16lVmO4VCgeLiYkPURkRERFQtKhyAtFqt3v8TERER1TZVOg1en/T0dEN1RURERFStqhSAFixYgJiYGOl+7969YW9vD3d3d5w+fdpgxRERERFVhyoFoGXLlsHDwwMAsHv3buzZswexsbHo3r073n33XYMWSERERGRoVToNPiUlRQpAP//8M/r06YOuXbvCy8sL/v7+Bi2QiIiIyNCqtAeoTp06uHr1KgAgNjYWQUFBAAAhBM8AIyIioidelfYA/ec//8GAAQPQqFEj3LlzB927dwcAnDx5Eg0bNjRogURERESGVqUA9Nlnn8HLywtXr17Fxx9/DCsrKwDAzZs3MXbsWIMWSERERGRoVQpAZmZmmDx5cqnpkyZNeuyCiIiIiKobfwqDiIiIZIc/hUFERESyw5/CICIiItkx2E9hEBEREdUWVQpAb731Fj7//PNS0xcvXoy33377cWsiIiIiqlZVCkCbN29G+/btS01v164dNm3a9NhFEREREVWnKgWgO3fuwNbWttR0Gxsb3L59+7GLIiIiIqpOVQpADRs2RGxsbKnpO3fuhLe392MXRURERFSdqnQhxPDwcIwfPx63bt1Cly5dAABxcXFYuHAhoqOjDVkfERERkcFVaQ/Qm2++iYULF2LFihXo3LkzOnfujO+++w5Lly7FiBEjKtXXkiVL4OXlBY1GA39/fxw9erTc9tHR0WjSpAnMzc3h4eGBSZMmIS8v77H6JCIiInmp8mnwY8aMwbVr15CamorMzExcunQJQ4YMqVQfMTExCA8PR0REBE6cOIEWLVogODgYaWlpett///33mDp1KiIiInDu3DmsWLECMTExeP/996vcJxEREclPlQNQUVER9uzZgy1btkAIAQC4ceMGsrOzK9xHVFQURowYgbCwMDRt2hTLli2DhYUFVq5cqbf9oUOH0L59ewwYMABeXl7o2rUr+vfvr7OHp7J9EhERkfxUKQBduXIFvr6+ePXVVzFu3DjcunULALBgwQK9P5KqT0FBAY4fP46goKD/FWNigqCgIMTHx+udp127djh+/LgUeC5duoQdO3YgJCSkyn0CQH5+PjIzM3VuRERE9PSqUgCaOHEiWrdujbt378Lc3Fya/tprryEuLq5Cfdy+fRvFxcVwdnbWme7s7IyUlBS98wwYMABz5sxBhw4dYGZmhgYNGqBTp07SIbCq9AkAkZGRsLW1lW4eHh4VWgciIiKqnaoUgPbv348ZM2ZApVLpTPfy8sL169cNUpg++/btw/z58/Hll1/ixIkT2LJlC7Zv3465c+c+Vr/Tpk1DRkaGdLt69aqBKiYiIqInUZVOg9dqtXp/8f3atWuwtrauUB8ODg5QKpVITU3VmZ6amgoXFxe988ycORODBw/G8OHDAQC+vr7IycnByJEjMX369Cr1CQBqtRpqtbpCdRMREVHtV6U9QF27dtW53o9CoUB2djYiIiKk8TiPolKp4Ofnp3PITKvVIi4uDgEBAXrnyc3NhYmJbslKpRIAIISoUp9EREQkP1XaA/Tpp5+iW7duaNq0KfLy8jBgwAAkJCTAwcEBP/zwQ4X7CQ8PR2hoKFq3bo22bdsiOjoaOTk5CAsLAwAMGTIE7u7uiIyMBAD07NkTUVFReP755+Hv74/ExETMnDkTPXv2lILQo/okIiIiqlIA8vDwwOnTpxETE4PTp08jOzsbw4YNw8CBA3UGRT9K3759cevWLcyaNQspKSlo2bIlYmNjpUHMycnJOnt8ZsyYAYVCgRkzZuD69etwdHREz549MW/evAr3SURERKQQJRfxqaDCwkL4+Pjg559/xrPPPltddRlVZmYmbG1tkZGRARsbG2OXQ0RE9NSY89NZrDyYhLGdGmBKNx+D9l2Z7+9KjwEyMzMr9dMTRERERLVJlQZBjxs3DgsWLEBRUZGh6yEiIiKqdlUaA/THH38gLi4Ov/zyC3x9fWFpaanz+JYtWwxSHBEREVF1qFIAsrOzw+uvv27oWoiIiIhqRKUCkFarxSeffIJ//vkHBQUF6NKlC2bPnl2pM7+IiIiIjK1SY4DmzZuH999/H1ZWVnB3d8fnn3+OcePGVVdtRERERNWiUgHo22+/xZdffoldu3Zh69at+Omnn7Bu3Tpotdrqqo+IiIjI4CoVgJKTk3V+6iIoKAgKhQI3btwweGFERERE1aVSAaioqAgajUZnmpmZGQoLCw1aFBEREVF1qtQgaCEEhg4dqvPL6Xl5eRg9erTOqfA8DZ6IiIieZJUKQKGhoaWmDRo0yGDFEBEREdWESgWgVatWVVcdRERERDWmSj+FQURERFSbMQARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DwRAWjJkiXw8vKCRqOBv78/jh49WmbbTp06QaFQlLr16NFDajN06NBSj3fr1q0mVoWIiIhqAVNjFxATE4Pw8HAsW7YM/v7+iI6ORnBwMC5cuAAnJ6dS7bds2YKCggLp/p07d9CiRQv07t1bp123bt2watUq6b5ara6+lSAiIqJaxeh7gKKiojBixAiEhYWhadOmWLZsGSwsLLBy5Uq97e3t7eHi4iLddu/eDQsLi1IBSK1W67SrU6dOTawOERER1QJGDUAFBQU4fvw4goKCpGkmJiYICgpCfHx8hfpYsWIF+vXrB0tLS53p+/btg5OTE5o0aYIxY8bgzp07ZfaRn5+PzMxMnRsRERE9vYwagG7fvo3i4mI4OzvrTHd2dkZKSsoj5z969CjOnDmD4cOH60zv1q0bvv32W8TFxWHBggX47bff0L17dxQXF+vtJzIyEra2ttLNw8Oj6itFRERETzyjjwF6HCtWrICvry/atm2rM71fv37S/319fdG8eXM0aNAA+/btw4svvliqn2nTpiE8PFy6n5mZyRBERET0FDPqHiAHBwcolUqkpqbqTE9NTYWLi0u58+bk5GD9+vUYNmzYI5fj7e0NBwcHJCYm6n1crVbDxsZG50ZERERPL6MGIJVKBT8/P8TFxUnTtFot4uLiEBAQUO68GzduRH5+PgYNGvTI5Vy7dg137tyBq6vrY9dMREREtZ/RzwILDw/H119/jTVr1uDcuXMYM2YMcnJyEBYWBgAYMmQIpk2bVmq+FStWoFevXqhbt67O9OzsbLz77rs4fPgwLl++jLi4OLz66qto2LAhgoODa2SdiIiI6Mlm9DFAffv2xa1btzBr1iykpKSgZcuWiI2NlQZGJycnw8REN6dduHABBw4cwC+//FKqP6VSiT///BNr1qxBeno63Nzc0LVrV8ydO5fXAiIiIiIAT0AAAoDx48dj/Pjxeh/bt29fqWlNmjSBEEJve3Nzc+zatcuQ5REREdFTxuiHwIiIiIhqGgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJzhMRgJYsWQIvLy9oNBr4+/vj6NGjZbbt1KkTFApFqVuPHj2kNkIIzJo1C66urjA3N0dQUBASEhJqYlWIiIioFjB6AIqJiUF4eDgiIiJw4sQJtGjRAsHBwUhLS9PbfsuWLbh586Z0O3PmDJRKJXr37i21+fjjj/H5559j2bJlOHLkCCwtLREcHIy8vLyaWi0iIiJ6ghk9AEVFRWHEiBEICwtD06ZNsWzZMlhYWGDlypV629vb28PFxUW67d69GxYWFlIAEkIgOjoaM2bMwKuvvormzZvj22+/xY0bN7B169YaXDMiIiJ6Uhk1ABUUFOD48eMICgqSppmYmCAoKAjx8fEV6mPFihXo168fLC0tAQBJSUlISUnR6dPW1hb+/v4V7pOIiIiebqbGXPjt27dRXFwMZ2dnnenOzs44f/78I+c/evQozpw5gxUrVkjTUlJSpD4e7rPksYfl5+cjPz9fup+ZmVnhdSAiIqLax+iHwB7HihUr4Ovri7Zt2z5WP5GRkbC1tZVuHh4eBqqQiIiInkRGDUAODg5QKpVITU3VmZ6amgoXF5dy583JycH69esxbNgwnekl81Wmz2nTpiEjI0O6Xb16tbKrQkRERLWIUQOQSqWCn58f4uLipGlarRZxcXEICAgod96NGzciPz8fgwYN0plev359uLi46PSZmZmJI0eOlNmnWq2GjY2Nzo2IiIieXkYdAwQA4eHhCA0NRevWrdG2bVtER0cjJycHYWFhAIAhQ4bA3d0dkZGROvOtWLECvXr1Qt26dXWmKxQKvP322/jwww/RqFEj1K9fHzNnzoSbmxt69epVU6tFRERETzCjB6C+ffvi1q1bmDVrFlJSUtCyZUvExsZKg5iTk5NhYqK7o+rChQs4cOAAfvnlF719TpkyBTk5ORg5ciTS09PRoUMHxMbGQqPRVPv6EBER0ZNPIYQQxi7iSZOZmQlbW1tkZGTwcBgREZEBzfnpLFYeTMLYTg0wpZuPQfuuzPd3rT4LjIiIiKgqGICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdowegJYsWQIvLy9oNBr4+/vj6NGj5bZPT0/HuHHj4OrqCrVajcaNG2PHjh3S47Nnz4ZCodC5+fj4VPdqEBERUS1iasyFx8TEIDw8HMuWLYO/vz+io6MRHByMCxcuwMnJqVT7goICvPTSS3BycsKmTZvg7u6OK1euwM7OTqdds2bNsGfPHum+qalRV5OIiIieMEZNBlFRURgxYgTCwsIAAMuWLcP27duxcuVKTJ06tVT7lStX4t9//8WhQ4dgZmYGAPDy8irVztTUFC4uLtVaOxEREdVeRjsEVlBQgOPHjyMoKOh/xZiYICgoCPHx8Xrn2bZtGwICAjBu3Dg4Ozvjueeew/z581FcXKzTLiEhAW5ubvD29sbAgQORnJxcbi35+fnIzMzUuREREdHTy2gB6Pbt2yguLoazs7POdGdnZ6SkpOid59KlS9i0aROKi4uxY8cOzJw5EwsXLsSHH34otfH398fq1asRGxuLpUuXIikpCR07dkRWVlaZtURGRsLW1la6eXh4GGYliYiI6IlUqwbHaLVaODk54auvvoJSqYSfnx+uX7+OTz75BBEREQCA7t27S+2bN28Of39/eHp6YsOGDRg2bJjefqdNm4bw8HDpfmZm5iNDkBACRUVFpfY+EREZi1KphKmpKRQKhbFLIXriGS0AOTg4QKlUIjU1VWd6ampqmeN3XF1dYWZmBqVSKU179tlnkZKSgoKCAqhUqlLz2NnZoXHjxkhMTCyzFrVaDbVaXeHaCwoKcPPmTeTm5lZ4HiKimmBhYQFXV1e9n4dE9D9GC0AqlQp+fn6Ii4tDr169ANzfwxMXF4fx48frnad9+/b4/vvvodVqYWJy/+jdP//8U+6bPTs7GxcvXsTgwYMNUrdWq0VSUhKUSiXc3NygUqn41xYRGZ0QAgUFBbh16xaSkpLQqFEj6XOSiEoz6iGw8PBwhIaGonXr1mjbti2io6ORk5MjnRU2ZMgQuLu7IzIyEgAwZswYLF68GBMnTsSECROQkJCA+fPn46233pL6nDx5Mnr27AlPT0/cuHEDERERUCqV6N+/v0FqLigogFarhYeHBywsLAzSJxGRIZibm8PMzAxXrlxBQUEBNBqNsUsiemIZNQD17dsXt27dwqxZs5CSkoKWLVsiNjZWGhidnJys8xeMh4cHdu3ahUmTJqF58+Zwd3fHxIkT8d5770ltrl27hv79++POnTtwdHREhw4dcPjwYTg6Ohq0dv5lRURPIn42EVWM0QdBjx8/vsxDXvv27Ss1LSAgAIcPHy6zv/Xr1xuqNCIiInpK8U8FIiIikh0GIKpWCoUCW7duNXjb2m7fvn1QKBRIT08HAKxevbrUT7rUdhcuXICLi0u51+Ciyvm///s/bN682dhlED0VGIBkYujQodKPw6pUKjRs2BBz5sxBUVFRtS735s2bOtdmMlTbx+Hl5SVtCwsLC/j6+uKbb76p9uXKzbRp0zBhwgRYW1uXeszHxwdqtVrvRU+9vLwQHR1davrs2bPRsmVLnWkpKSmYMGECvL29oVar4eHhgZ49eyIuLs5Qq1HK33//jddff116HemrVZ8///wTHTt2hEajgYeHBz7++ONSbTZu3AgfHx9oNBr4+vrq/NAzAMyYMQNTp06FVqs1xKoQyRoDkIx069YNN2/eREJCAt555x3Mnj0bn3zyid62BQUFBlmmi4tLha+xVJm2j2vOnDm4efMmzpw5g0GDBmHEiBHYuXNnjSz7SWGo51if5ORk/Pzzzxg6dGipxw4cOIB79+7hjTfewJo1a6q8jMuXL8PPzw979+7FJ598gr/++guxsbHo3Lkzxo0b9xjVly83Nxfe3t746KOPKvybg5mZmejatSs8PT1x/PhxfPLJJ5g9eza++uorqc2hQ4fQv39/DBs2DCdPnkSvXr3Qq1cvnDlzRmrTvXt3ZGVlye61SlQdGIAMQAiB3IKiGr8JISpVp1qthouLCzw9PTFmzBgEBQVh27ZtAO7vIerVqxfmzZsHNzc3NGnSBABw9epV9OnTB3Z2drC3t8err76Ky5cv6/S7cuVKNGvWDGq1Gq6urjqD2h88rFVQUIDx48fD1dUVGo0Gnp6e0iUOHm4LAH/99Re6dOkCc3Nz1K1bFyNHjkR2drb0eEnNn376KVxdXVG3bl2MGzcOhYWFj9wW1tbWcHFxgbe3N9577z3Y29tj9+7d0uPp6ekYPnw4HB0dYWNjgy5duuD06dM6ffz0009o06YNNBoNHBwc8Nprr0mPrV27Fq1bt5aWM2DAAKSlpT2yrvKUnOFob28PS0tLtG7dGkeOHNHZFg96++230alTJ+l+p06dMH78eLz99ttwcHBAcHAwBgwYgL59++rMV1hYCAcHB3z77bcA7l/7KjIyEvXr14e5uTlatGiBTZs2lVvrhg0b0KJFC7i7u5d6bMWKFRgwYAAGDx6MlStXVmFL3Dd27FgoFAocPXoUr7/+Oho3boxmzZohPDy83BMlHlebNm3wySefoF+/fhUO7OvWrUNBQYH0XunXrx/eeustREVFSW0WLVqEbt264d1338Wzzz6LuXPnolWrVli8eLHURqlUIiQkhCd7EBmA0c8CexrcKyxG01m7any5Z+cEw0JV9afQ3Nwcd+7cke7HxcXBxsZGCgKFhYUIDg5GQEAA9u/fD1NTU3z44Yfo1q0b/vzzT6hUKixduhTh4eH46KOP0L17d2RkZODgwYN6l/f5559j27Zt2LBhA5555hlcvXoVV69e1ds2JydHWvYff/yBtLQ0DB8+HOPHj8fq1auldr/++itcXV3x66+/IjExEX379kXLli0xYsSICm0DrVaLH3/8EXfv3tW5mGbv3r1hbm6OnTt3wtbWFsuXL8eLL76If/75B/b29ti+fTtee+01TJ8+Hd9++y0KCgp0DlcUFhZi7ty5aNKkCdLS0hAeHo6hQ4eWOqRRUdnZ2QgMDIS7uzu2bdsGFxcXnDhxotKHQtasWYMxY8ZIz1FiYiJ69+6N7OxsWFlZAQB27dqF3NxcKdBFRkbiu+++w7Jly9CoUSP8/vvvGDRoEBwdHREYGKh3Ofv370fr1q1LTc/KysLGjRtx5MgR+Pj4ICMjA/v370fHjh0rtR7//vsvYmNjMW/ePFhaWpZ6vLzxVOvWrcOoUaPK7X/nzp2Vrqk88fHxeOGFF3ReY8HBwViwYAHu3r2LOnXqID4+XucneUraPDwurm3btvjoo48MVhuRXDEAyZAQAnFxcdi1axcmTJggTbe0tMQ333wjfUh/99130Gq1+Oabb6SrXa9atQp2dnbYt28funbtig8//BDvvPMOJk6cKPXTpk0bvctNTk5Go0aN0KFDBygUCnh6epZZ4/fff4+8vDx8++230hfc4sWL0bNnTyxYsEC6VlSdOnWwePFiKJVK+Pj4oEePHoiLi3tkAHrvvfcwY8YM5Ofno6ioCPb29hg+fDiA+4dojh49irS0NOkv/E8//RRbt27Fpk2bMHLkSMybNw/9+vXDBx98IPXZokUL6f9vvvmm9H9vb298/vnnaNOmjU7QqIzvv/8et27dwh9//AF7e3sAQMOGDSvdT6NGjXTGnjRo0ACWlpb48ccfpaulf//993jllVdgbW2N/Px8zJ8/H3v27EFAQIC0PgcOHMDy5cvLDEBXrlzRG4DWr1+PRo0aoVmzZgCAfv36YcWKFZUOG4mJiRBCwMfHp1LzAcArr7wCf3//ctvo23P1OFJSUlC/fn2daSWv4ZSUFNSpUwcpKSkV+nFoNzc3XL16VeeK+ERUeQxABmBupsTZOcFGWW5l/Pzzz7CyskJhYSG0Wi0GDBiA2bNnS4/7+vrq/IV6+vRpJCYmlhrEmpeXh4sXLyItLQ03btzAiy++WKHlDx06FC+99BKaNGmCbt264eWXX0bXrl31tj137hxatGih89d9+/btodVqceHCBemLolmzZjq/Defq6oq//voLADB//nzMnz9feuzs2bN45plnAADvvvsuhg4dips3b+Ldd9/F2LFjpUBx+vRpZGdno27dujo13bt3DxcvXgQAnDp1qtyQdfz4ccyePRunT5/G3bt3pT01ycnJaNq0aYW214NOnTqF559/Xgo/VeXn56dz39TUFH369MG6deswePBg5OTk4L///a90iCUxMRG5ubl46aWXdOYrKCjA888/X+Zy7t27p/cqxCtXrsSgQYOk+4MGDUJgYCC++OILvYOly1LZw78Psra2rtSynjTm5ubQarXIz8+Hubm5scshqrUYgAxAoVA81qGomtK5c2csXboUKpUKbm5uMDXVrfnhQwnZ2dnw8/PDunXrSvXl6OhY6b8+W7VqhaSkJOzcuRN79uxBnz59EBQU9MjxJOUxMzPTua9QKKSwMXr0aPTp00d6zM3NTfq/g4MDGjZsiIYNG2Ljxo3w9fVF69at0bRpU2RnZ8PV1VXvhThLDq2U98VTcvguODgY69atg6OjI5KTkxEcHFzlgceP+qIzMTEpFQr0jYXSd7ho4MCBCAwMRFpaGnbv3g1zc3N069YNAKQxV9u3by+1V6S88S8ODg64e/euzrSzZ8/i8OHDOHr0qM7V24uLi7F+/XopUNrY2CAjI6NUn+np6bC1tQVwf0+WQqHA+fPny6yhLMY4BObi4qL3h59LHiuvzcMDrf/9919YWloy/BA9pif/W5sMxtLSslKHTVq1aoWYmBg4OTnBxsZGbxsvLy/ExcWhc+fOFerTxsYGffv2Rd++ffHGG2+gW7du+Pfff0vt2Xj22WexevVq5OTkSF/aBw8ehImJiTRA+1Hs7e0rtMfEw8MDffv2xbRp0/Df//4XrVq1QkpKCkxNTeHl5aV3nubNmyMuLk763boHnT9/Hnfu3MFHH30EDw8PAMCxY8cqVHNZmjdvjm+++UbvtgLuB9IHzxYC7u81ejgg6tOuXTt4eHggJiYGO3fuRO/evaX5mjZtCrVajeTk5DIPd+nz/PPP4+zZszrTVqxYgRdeeAFLlizRmb5q1SqsWLFCCkBNmjTB8ePHS/V54sQJ6bm3t7dHcHAwlixZgrfeeqtUsEtPTy9zHJAxDoEFBARg+vTpKCwslLbt7t270aRJE9SpU0dqExcXh7fffluab/fu3dKhxxJnzpwpd+8bEVUMDyBTmQYOHAgHBwe8+uqr2L9/P5KSkrBv3z689dZbuHbtGoD712ZZuHAhPv/8cyQkJODEiRP44osv9PYXFRWFH374AefPn8c///yDjRs3wsXFRe8X1cCBA6HRaBAaGoozZ87g119/xYQJEzB48OBS4yQMYeLEifjpp59w7NgxBAUFISAgAL169cIvv/yCy5cv49ChQ5g+fboUZCIiIvDDDz8gIiIC586dw19//YUFCxYAAJ555hmoVCp88cUXuHTpErZt24a5c+c+Vn39+/eHi4sLevXqhYMHD+LSpUvYvHkz4uPjAQBdunTBsWPH8O233yIhIQERERGlAlF5BgwYgGXLlmH37t0YOHCgNN3a2hqTJ0/GpEmTsGbNGly8eFF6jss7hT04OBjx8fEoLi4GcH9v1Nq1a9G/f38899xzOrfhw4fjyJEj+PvvvwEAkyZNwvbt2zFv3jycO3cOZ86cwfTp0xEfH68z1mzJkiUoLi5G27ZtsXnzZiQkJODcuXP4/PPPS4WGB1lbW0t7/8q6lbd3paCgAKdOncKpU6dQUFCA69ev49SpU0hMTJTaLF68WOfQ8IABA6BSqTBs2DD8/fffiImJwaJFi3QGPU+cOBGxsbFYuHAhzp8/j9mzZ+PYsWOlfipo//79ZR46JqoNzJQKqE1NYGqiMG4hgkrJyMgQAERGRkapx+7duyfOnj0r7t27Z4TKqi40NFS8+uqrlX785s2bYsiQIcLBwUGo1Wrh7e0tRowYobNtli1bJpo0aSLMzMyEq6urmDBhgvQYAPHjjz8KIYT46quvRMuWLYWlpaWwsbERL774ojhx4oTetkII8eeff4rOnTsLjUYj7O3txYgRI0RWVla5NU+cOFEEBgaWuy08PT3FZ599Vmp6cHCw6N69uxBCiMzMTDFhwgTh5uYmzMzMhIeHhxg4cKBITk6W2m/evFm0bNlSqFQq4eDgIP7zn/9Ij33//ffCy8tLqNVqERAQILZt2yYAiJMnTwohhPj1118FAHH37l0hhBCrVq0Stra25dZ9+fJl8frrrwsbGxthYWEhWrduLY4cOSI9PmvWLOHs7CxsbW3FpEmTxPjx43W2RWBgoJg4caLevs+ePSsACE9PT6HVanUe02q1Ijo6WnqOHR0dRXBwsPjtt9/KrLWwsFC4ubmJ2NhYIYQQmzZtEiYmJiIlJUVv+2effVZMmjRJur9r1y7Rvn17UadOHVG3bl3RqVMnvcu7ceOGGDdunPD09BQqlUq4u7uLV155Rfz6669l1va4kpKSBIBStwe3dUREhPD09NSZ7/Tp06JDhw5CrVYLd3d38dFHH5Xqe8OGDaJx48ZCpVKJZs2aie3bt+s8fu3aNWFmZiauXr1aZn219TOKyBDK+/5+mEKIxxhN+JTKzMyEra0tMjIySh36ycvLQ1JSEurXr693kCcR3bdkyRJs27YNu3bV/CUinlbvvfce7t69q3MBxYfxM4rkrLzv74dxDBARVYtRo0YhPT0dWVlZtfqsqyeJk5NTqWsFEVHVMAARUbUwNTXF9OnTjV3GU+Wdd94xdglETw0OgiYiIiLZYQAiIiIi2WEAqiKOHSeiJxE/m4gqhgGokkouYpabm2vkSoiISiv5bKrIRTCJ5IyDoCtJqVTCzs4OaWlpAAALCwvph0KJiIxFCIHc3FykpaXBzs5O5zfyiKg0BqAqKPltnpIQRET0pLCzsyv1+2FEVBoDUBUoFAq4urrCyclJ7w9OEhEZg5mZGff8EFUQA9BjUCqV/LAhIiKqhTgImoiIiGSHAYiIiIhkhwGIiIiIZIdjgPQouZBYZmamkSshIiKiiir53q7IBUEZgPTIysoCAHh4eBi5EiIiIqqsrKws2NralttGIXjd9FK0Wi1u3LgBa2trg1/kMDMzEx4eHrh69SpsbGwM2jf9D7dzzeB2rhnczjWD27lmVOd2FkIgKysLbm5uMDEpf5QP9wDpYWJignr16lXrMmxsbPgGqwHczjWD27lmcDvXDG7nmlFd2/lRe35KcBA0ERERyQ4DEBEREckOA1ANU6vViIiIgFqtNnYpTzVu55rB7VwzuJ1rBrdzzXhStjMHQRMREZHscA8QERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DUDVYsmQJvLy8oNFo4O/vj6NHj5bbfuPGjfDx8YFGo4Gvry927NhRQ5XWbpXZzl9//TU6duyIOnXqoE6dOggKCnrk80L3Vfb1XGL9+vVQKBTo1atX9Rb4lKjsdk5PT8e4cePg6uoKtVqNxo0b87OjAiq7naOjo9GkSROYm5vDw8MDkyZNQl5eXg1VWzv9/vvv6NmzJ9zc3KBQKLB169ZHzrNv3z60atUKarUaDRs2xOrVq6u9TggyqPXr1wuVSiVWrlwp/v77bzFixAhhZ2cnUlNT9bY/ePCgUCqV4uOPPxZnz54VM2bMEGZmZuKvv/6q4cprl8pu5wEDBoglS5aIkydPinPnzomhQ4cKW1tbce3atRquvHap7HYukZSUJNzd3UXHjh3Fq6++WjPF1mKV3c75+fmidevWIiQkRBw4cEAkJSWJffv2iVOnTtVw5bVLZbfzunXrhFqtFuvWrRNJSUli165dwtXVVUyaNKmGK69dduzYIaZPny62bNkiAIgff/yx3PaXLl0SFhYWIjw8XJw9e1Z88cUXQqlUitjY2GqtkwHIwNq2bSvGjRsn3S8uLhZubm4iMjJSb/s+ffqIHj166Ezz9/cXo0aNqtY6a7vKbueHFRUVCWtra7FmzZrqKvGpUJXtXFRUJNq1aye++eYbERoaygBUAZXdzkuXLhXe3t6ioKCgpkp8KlR2O48bN0506dJFZ1p4eLho3759tdb5NKlIAJoyZYpo1qyZzrS+ffuK4ODgaqxMCB4CM6CCggIcP34cQUFB0jQTExMEBQUhPj5e7zzx8fE67QEgODi4zPZUte38sNzcXBQWFsLe3r66yqz1qrqd58yZAycnJwwbNqwmyqz1qrKdt23bhoCAAIwbNw7Ozs547rnnMH/+fBQXF9dU2bVOVbZzu3btcPz4cekw2aVLl7Bjxw6EhITUSM1yYazvQf4YqgHdvn0bxcXFcHZ21pnu7OyM8+fP650nJSVFb/uUlJRqq7O2q8p2fth7770HNze3Um86+p+qbOcDBw5gxYoVOHXqVA1U+HSoyna+dOkS9u7di4EDB2LHjh1ITEzE2LFjUVhYiIiIiJoou9apynYeMGAAbt++jQ4dOkAIgaKiIowePRrvv/9+TZQsG2V9D2ZmZuLevXswNzevluVyDxDJzkcffYT169fjxx9/hEajMXY5T42srCwMHjwYX3/9NRwcHIxdzlNNq9XCyckJX331Ffz8/NC3b19Mnz4dy5YtM3ZpT5V9+/Zh/vz5+PLLL3HixAls2bIF27dvx9y5c41dGhkA9wAZkIODA5RKJVJTU3Wmp6amwsXFRe88Li4ulWpPVdvOJT799FN89NFH2LNnD5o3b16dZdZ6ld3OFy9exOXLl9GzZ09pmlarBQCYmpriwoULaNCgQfUWXQtV5fXs6uoKMzMzKJVKadqzzz6LlJQUFBQUQKVSVWvNtVFVtvPMmTMxePBgDB8+HADg6+uLnJwcjBw5EtOnT4eJCfchGEJZ34M2NjbVtvcH4B4gg1KpVPDz80NcXJw0TavVIi4uDgEBAXrnCQgI0GkPALt37y6zPVVtOwPAxx9/jLlz5yI2NhatW7euiVJrtcpuZx8fH/z11184deqUdHvllVfQuXNnnDp1Ch4eHjVZfq1Rlddz+/btkZiYKAVMAPjnn3/g6urK8FOGqmzn3NzcUiGnJHQK/oymwRjte7Bah1jL0Pr164VarRarV68WZ8+eFSNHjhR2dnYiJSVFCCHE4MGDxdSpU6X2Bw8eFKampuLTTz8V586dExERETwNvgIqu50/+ugjoVKpxKZNm8TNmzelW1ZWlrFWoVao7HZ+GM8Cq5jKbufk5GRhbW0txo8fLy5cuCB+/vln4eTkJD788ENjrUKtUNntHBERIaytrcUPP/wgLl26JH755RfRoEED0adPH2OtQq2QlZUlTp48KU6ePCkAiKioKHHy5Elx5coVIYQQU6dOFYMHD5bal5wG/+6774pz586JJUuW8DT42uqLL74QzzzzjFCpVKJt27bi8OHD0mOBgYEiNDRUp/2GDRtE48aNhUqlEs2aNRPbt2+v4Yprp8psZ09PTwGg1C0iIqLmC69lKvt6fhADUMVVdjsfOnRI+Pv7C7VaLby9vcW8efNEUVFRDVdd+1RmOxcWForZs2eLBg0aCI1GIzw8PMTYsWPF3bt3a77wWuTXX3/V+3lbsm1DQ0NFYGBgqXlatmwpVCqV8Pb2FqtWrar2OhVCcD8eERERyQvHABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAAREVWQQqHA1q1bAQCXL1+GQqHAqVOnjFoTEVUNAxAR1QpDhw6FQqGAQqGAmZkZ6tevjylTpiAvL8/YpRFRLcRfgyeiWqNbt25YtWoVCgsLcfz4cYSGhkKhUGDBggXGLo2IahnuASKiWkOtVsPFxQUeHh7o1asXgoKCsHv3bgD3f9k7MjIS9evXh7m5OVq0aIFNmzbpzP/333/j5Zdfho2NDaytrdGxY0dcvHgRAPDHH3/gpZdegoODA2xtbREYGIgTJ07U+DoSUc1gACKiWunMmTM4dOgQVCoVACAyMhLffvstli1bhr///huTJk3CoEGD8NtvvwEArl+/jhdeeAFqtRp79+7F8ePH8eabb6KoqAgAkJWVhdDQUBw4cACHDx9Go0aNEBISgqysLKOtIxFVHx4CI6Ja4+eff4aVlRWKioqQn58PExMTLF68GPn5+Zg/fz727NmDgIAAAIC3tzcOHDiA5cuXIzAwEEuWLIGtrS3Wr18PMzMzAEDjxo2lvrt06aKzrK+++gp2dnb47bff8PLLL9fcShJRjWAAIqJao3Pnzli6dClycnLw2WefwdTUFK+//jr+/vtv5Obm4qWXXtJpX1BQgOeffx4AcOrUKXTs2FEKPw9LTU3FjBkzsG/fPqSlpaG4uBi5ublITk6u9vUioprHAEREtYalpSUaNmwIAFi5ciVatGiBFStW4LnnngMAbN++He7u7jrzqNVqAIC5uXm5fYeGhuLOnTtYtGgRPD09oVarERAQgIKCgmpYEyIyNgYgIqqVTExM8P777yM8PBz//PMP1Go1kpOTERgYqLd98+bNsWbNGhQWFurdC3Tw4EF8+eWXCAkJAQBcvXoVt2/frtZ1ICLj4SBoIqq1evfuDaVSieXLl2Py5MmYNGkS1qxZg4sXL+LEiRP44osvsGbNGgDA+PHjkZmZiX79+uHYsWNISEjA2rVrceHCBQBAo0aNsHbtWpw7dw5HjhzBwIEDH7nXiIhqL+4BIqJay9TUFOPHj8fHH3+MpKQkODo6IjIyEpcuXYKdnR1atWqF999/HwBQt25d7N27F++++y4CAwOhVCrRsmVLtG/fHgCwYsUKjBw5Eq1atYKHhwfmz5+PyZMnG3P1iKgaKYQQwthFEBEREdUkHgIjIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZ+X+CAMzSQJC5DQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 21) Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy."
      ],
      "metadata": {
        "id": "R4urBo-BVB13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Define a list of solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "# Loop through the solvers and train a Logistic Regression model for each\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with solver {solver}: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nne7vkcVNW6",
        "outputId": "347d6495-7612-4627-eada-015beca412a5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with solver liblinear: 0.8333333333333334\n",
            "Accuracy with solver saga: 0.9666666666666667\n",
            "Accuracy with solver lbfgs: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 22) Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "rD8IDKueVSL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9HqTPXkViJb",
        "outputId": "a9a01f71-0afe-4d1f-fd03-0b20a305debb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.9439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 23) Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "YLA8jbirVx5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression on raw data\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "print(f\"Accuracy on raw data: {accuracy_raw}\")\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy on standardized data: {accuracy_scaled}\")\n",
        "\n",
        "# Compare the accuracy\n",
        "print(f\"Difference in accuracy: {accuracy_scaled - accuracy_raw}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObttMoDoV8lL",
        "outputId": "b4313281-63d3-4786-9bf5-88513eef3b79"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 1.0\n",
            "Accuracy on standardized data: 1.0\n",
            "Difference in accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 24) Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
      ],
      "metadata": {
        "id": "fm7vBLqWWCTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Define a range of C values to test\n",
        "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Create a dictionary to store the cross-validation scores for each C value\n",
        "cv_scores = {}\n",
        "\n",
        "# Perform cross-validation for each C value\n",
        "for C in C_values:\n",
        "  model = LogisticRegression(C=C, max_iter=1000)\n",
        "  scores = cross_val_score(model, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
        "  cv_scores[C] = scores.mean()\n",
        "\n",
        "# Find the C value with the highest cross-validation score\n",
        "best_C = max(cv_scores, key=cv_scores.get)\n",
        "print(f\"Optimal C value: {best_C}\")\n",
        "\n",
        "# Train a Logistic Regression model with the best C value\n",
        "model = LogisticRegression(C=best_C, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with optimal C value: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD6zWOYdWKid",
        "outputId": "ee88d840-3fa4-4e80-8ab6-6511cde7c3ae"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C value: 1\n",
            "Accuracy with optimal C value: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 25) Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "WHKkjNIXXdxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Create and train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model using joblib\n",
        "joblib.dump(model, 'logistic_regression_model.joblib')\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = joblib.load('logistic_regression_model.joblib')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the loaded model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of the loaded model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zku33TT_Xn9_",
        "outputId": "33ac6232-ab15-4145-eb8c-befc2a27eea9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the loaded model: 0.9736842105263158\n"
          ]
        }
      ]
    }
  ]
}